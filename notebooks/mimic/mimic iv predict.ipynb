{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install openai langchain  tiktoken  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict \n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openai api key config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "openai.api_base = \"YOUR_API_BASE\"\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version ='2023-03-15-preview'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the preprocessed mimic III file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_9 = '/PATH/TO/YOUR/FILE/mimiciv_9.pkl'\n",
    "filename_10 = '/PATH/TO/YOUR/FILE/mimiciv_10.pkl'\n",
    "mimiciv_9 = pd.read_pickle(filename_9)\n",
    "mimiciv_10 = pd.read_pickle(filename_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9_dict = {}\n",
    "for index, row in mimiciv_9.iterrows():\n",
    "  text = re.sub(r\"\\n+|\\[]+\", \" \", row['text'])\n",
    "  \n",
    "  if row['_id'] in icd9_dict:\n",
    "      icd9_dict[row['_id']].append((text, row['target']))\n",
    "  else:\n",
    "      icd9_dict[row['_id']] = [(text, row['target'])]\n",
    "\n",
    "\n",
    "icd10_dict = {}\n",
    "for index, row in mimiciv_10.iterrows():\n",
    "  text = re.sub(r\"\\n+|\\[]+\", \" \", row['text'])\n",
    "  if row['_id'] in icd10_dict:\n",
    "      icd10_dict[row['_id']].append((text, row['target']))\n",
    "  else:\n",
    "      icd10_dict[row['_id']] = [(text, row['target'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_keys9 = list(icd9_dict.keys())[:300]\n",
    "test_keys10 = list(icd10_dict.keys())[:300]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tiktoken tokenizer for adjusting number of tokens passed to various openai models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tik_tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "def tiktoken_len(text):\n",
    "  tokens = tik_tokenizer.encode(text, disallowed_special = ())\n",
    "  return len(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create schemas for prompting using langchain's ResponseSchema module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_schema = ResponseSchema(name = 'diseases', description=\"this is focuses on medical history of the patient.It involves extracting information about diseases, disorders, or medical conditions that have affected the patient\")\n",
    "response_schemas = [disease_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "template_string = \"\"\"You are an expert in information extraction from clinical notes. Given a clinical note, you extract diseases/disorders/procedures and return all as a single python list of strings like [\"disease\",\"disease\",\"procedure\"]. Here is the note: {text_note}. {format_instructions}\n",
    "\"\"\"\n",
    "disease_prompt = ChatPromptTemplate(messages=[HumanMessagePromptTemplate.from_template(template_string)],\n",
    "                            input_variables=['text_note'],\n",
    "                            partial_variables={\"format_instructions\":format_instructions},\n",
    "                            output_parser=output_parser\n",
    ")\n",
    "\n",
    "evidence_schema = ResponseSchema(name = 'evidence', description=\"\"\"You are an expert fact checker. Your job is to fact check the {diseases} provided based on the full input text given and return a python list of lists. Individual lists have\n",
    "                                            evidence text span next to each of the disease. Your job is to determine whether each of the values in the list {diseases} is correct or not. Find the span of text (a one sentence) from the \n",
    "                                            {text_input} as an evidence.  Add the text span evidence that makes the answer True or False. Dont add any extra text.\n",
    "                                             Example output is here ###\n",
    "                                              [\n",
    "                                             [\"ESRD\",  \"ESRD secondary to hypertensive nephrosclerosis \",\"True\"],\n",
    "                                            [\"DM\", \" DM, on glipizide at home\",\"True\"],\n",
    "                                            [\"Hypertension\", \"high blood pressure ruled out\", \"False\"]\n",
    "                                                        ]                               \"\"\")\n",
    "response_schemas = [evidence_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "template_string = \"\"\"You are an expert fact checker. Given a clinical note and list of diseases and procedures, you verify by extracting evidence and return all as a single python list of strings. Here is the note: {text_note} and list of diseases and procedures. {format_instructions}\n",
    "\"\"\"\n",
    "evidence_prompt = ChatPromptTemplate(messages=[HumanMessagePromptTemplate.from_template(template_string)],\n",
    "                            input_variables=['text_note','diseases'],\n",
    "                            partial_variables={\"format_instructions\":format_instructions},\n",
    "                            output_parser=output_parser\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "entail_schema = ResponseSchema(name = 'entail', description=\"this focuses on checking wether the disease/procedure can be entailed from the text fragment in the provided {text_note} in the format [disease, text fragment] \")\n",
    "response_schemas = [entail_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "template_string = \"\"\" You are an expert textual entailment agent. Textual Entailment(aka Natural Language inference) is directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. Your job is to check wether the disease can be entailed from the text in the provided {text_note} in the format (disease, text fragment).Dont extrapolate, entail only based on the provided text fragment. If the disease can be entailed from the text fragment based on the {text_note}, add the diseases to the output list. Return the disease list of all diseases that can be entailed. All values must be in a string format inside double quotations . Here is the note: {text_note}. {format_instructions}\n",
    "\"\"\"\n",
    "entail_prompt = ChatPromptTemplate(messages=[HumanMessagePromptTemplate.from_template(template_string)],\n",
    "                            input_variables=['text_note'],\n",
    "                            partial_variables={\"format_instructions\":format_instructions},\n",
    "                            output_parser=output_parser\n",
    ")\n",
    "\n",
    "omissions_schema = ResponseSchema(name = 'omissions', description=\"this focuses on finding all the missing disease/procedure from the provided {text_note} that are not in the list {diseases} \")\n",
    "response_schemas = [omissions_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "template_string = \"\"\" You are an expert disease inspector. Your job is to find all possible diseases/procedures in the given {text_note} exhaustively and return in a python list of strings. Your response should be in the form of \n",
    "                                            python list with all the diseases/procedures that you can verify do exist in the {text_note}. Make sure to return the disease/procedures exhaustively.Dont include a disease/procedure if it is in the {diseases} list. Return only unique diseases/procedures. All diseases/procedures in the list must be in a string format.  Here is the note: {text_note} and the list of diseases/procedures {diseases}. {format_instructions}\n",
    "\"\"\"\n",
    "omissions_prompt = ChatPromptTemplate(messages=[HumanMessagePromptTemplate.from_template(template_string)],\n",
    "                            input_variables=['text_note','diseases'],\n",
    "                            partial_variables={\"format_instructions\":format_instructions},\n",
    "                            output_parser=output_parser\n",
    ")\n",
    "\n",
    "\n",
    "icd_schema = ResponseSchema(name = 'icd', description=\"this focuses on assining ICD 9 codes for all the diseases/procedures listed in the {diseases} based on the context in {text_note} \")\n",
    "response_schemas = [icd_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "template_string = \"\"\"You are an expert clinical data encoder.  your job is to extract ICD 9 codes for all the diseases/procedures listed in {diseases} based ont the context in {text_note}. Then return a python list of strings containing all the ICD 9 codes you assigned.{format_instructions}\n",
    "\"\"\"\n",
    "icd_prompt = ChatPromptTemplate(messages=[HumanMessagePromptTemplate.from_template(template_string)],\n",
    "                            input_variables=['text_note','diseases'],\n",
    "                            partial_variables={\"format_instructions\":format_instructions},\n",
    "                            output_parser=output_parser\n",
    ")\n",
    "\n",
    "icd_schema_10 = ResponseSchema(name = 'icd', description=\"this focuses on assining ICD 10 codes for all the diseases/procedures listed in the {diseases} based on the context in {text_note} \")\n",
    "response_schemas = [icd_schema_10]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "template_string = \"\"\"You are an expert clinical data encoder.  your job is to extract ICD 10 codes for all the diseases/procedures listed in {diseases} based ont the context in {text_note}. Then return a python list of strings containing all the ICD 10 codes you assigned.{format_instructions}\n",
    "\"\"\"\n",
    "icd_prompt_10 = ChatPromptTemplate(messages=[HumanMessagePromptTemplate.from_template(template_string)],\n",
    "                            input_variables=['text_note','diseases'],\n",
    "                            partial_variables={\"format_instructions\":format_instructions},\n",
    "                            output_parser=output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diseases(note):\n",
    "  for i in range(3):\n",
    "    try:\n",
    "      chain = LLMChain(llm=llm,prompt=disease_prompt)\n",
    "      diseases = chain.predict_and_parse(text_note = note)\n",
    "      return diseases['diseases']\n",
    "    except openai.error.RateLimitError:\n",
    "      time.sleep(5)  \n",
    "    except Exception as e:\n",
    "      print(e) \n",
    "\n",
    "def get_evidence(note,diseases):\n",
    "  for i in range(3):\n",
    "    try:\n",
    "      chain = LLMChain(llm=llm,prompt=evidence_prompt)\n",
    "      evidence = chain.predict_and_parse(text_note = note, diseases = diseases)\n",
    "      return evidence  \n",
    "    except openai.error.RateLimitError:\n",
    "      time.sleep(5)  \n",
    "    except Exception as e:\n",
    "      print(e) \n",
    "\n",
    "def does_ential(evidence):\n",
    "  for i in range(3):\n",
    "    try:\n",
    "      chain = LLMChain(llm=llm,prompt=entail_prompt)\n",
    "      evidence_list = [(x[0],x[1]) for x in evidence['evidence'] if x[2].lower()=='true']\n",
    "      entail = chain.predict_and_parse( text_note = evidence_list)\n",
    "      verified = entail['entail']\n",
    "      return verified  \n",
    "    except openai.error.RateLimitError:\n",
    "      time.sleep(5)  \n",
    "    except Exception as e:\n",
    "      print(e) \n",
    "\n",
    "def find_omissions(note, verified):\n",
    "  for i in range(3):\n",
    "    try:\n",
    "      chain = LLMChain(llm=llm,prompt=omissions_prompt)\n",
    "      omissions = chain.predict_and_parse( text_note = note, diseases = verified)\n",
    "      return omissions['omissions']  \n",
    "    except openai.error.RateLimitError:\n",
    "      time.sleep(5)  \n",
    "    except Exception as e:\n",
    "      print(e)   \n",
    "\n",
    "def get_icds(note, diseases):\n",
    "  for _ in range(3):\n",
    "    try:\n",
    "      chain = LLMChain(llm=llm,prompt=icd_prompt)\n",
    "      icds = chain.predict_and_parse( text_note = note, diseases = diseases)\n",
    "      return icds\n",
    "    except openai.error.RateLimitError:\n",
    "      time.sleep(5)  \n",
    "    except Exception as e:\n",
    "      print(e)   \n",
    "\n",
    "def get_icds_10(note, diseases):\n",
    "  for _ in range(3):\n",
    "    try:\n",
    "      chain = LLMChain(llm=llm,prompt=icd_prompt_10)\n",
    "      icds = chain.predict_and_parse( text_note = note, diseases = diseases)\n",
    "      return icds\n",
    "    except openai.error.RateLimitError:\n",
    "      time.sleep(5)  \n",
    "    except Exception as e:\n",
    "      print(e)  \n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics_9(output, icd):\n",
    "    tn, fn, fp, acc, total_pred, total_y = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "    for k, vv in output.items():\n",
    "        try:\n",
    "          new_v = vv['icd']\n",
    "        except:\n",
    "          continue  \n",
    "        y_true = {str(x) for x in mimiciii_dict[k] if str(x) in icd}\n",
    "        if not y_true:\n",
    "          continue\n",
    "        v = {xx.strip() for xx in new_v if xx.strip() in icd}\n",
    "        \n",
    "        neg = set(icd).difference(y_true)\n",
    "        potential_neg = set(icd).difference(v)\n",
    "\n",
    "        tn += len(neg.intersection(potential_neg))\n",
    "        fn += len(potential_neg.intersection(y_true))\n",
    "        fp += len(v.intersection(neg))\n",
    "        total_y += len(y_true)\n",
    "        acc += len(v.intersection(y_true))\n",
    "        total_pred += len(v)\n",
    "\n",
    "    P = acc / total_pred\n",
    "    R = acc / total_y\n",
    "    A = (acc + tn) / (acc + tn + fn + fp)\n",
    "\n",
    "    #return {'P': P, 'R': R, 'A': A}\n",
    "\n",
    "    print(\"total correct:\", acc, \"total pred:\",total_pred, \"total true:\", total_y)  \n",
    "    print('precision is ',P)\n",
    "    print('recall is ',R)  \n",
    "    print('F1 is ',2*((P*R)/(P+R)))\n",
    "    print('Accuracy is ',A)\n",
    "    \n",
    "def calculate_metrics_10(output, icd):\n",
    "    tn, fn, fp, acc, total_pred, total_y = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "    for k, vv in output.items():\n",
    "        try:\n",
    "          new_v = vv['icd']\n",
    "        except:\n",
    "          continue  \n",
    "        y_true = {str(x).lower() for x in icd10_dict[k][0][1] if str(x).lower() in icd}\n",
    "        if not y_true:\n",
    "          continue\n",
    "        v = {xx.strip().lower() for xx in new_v if xx.strip().lower() in icd}\n",
    "        \n",
    "        neg = set(icd).difference(y_true)\n",
    "        potential_neg = set(icd).difference(v)\n",
    "\n",
    "        tn += len(neg.intersection(potential_neg))\n",
    "        fn += len(potential_neg.intersection(y_true))\n",
    "        fp += len(v.intersection(neg))\n",
    "        total_y += len(y_true)\n",
    "        acc += len(v.intersection(y_true))\n",
    "        total_pred += len(v)\n",
    "\n",
    "    P = acc / total_pred\n",
    "    R = acc / total_y\n",
    "    A = (acc + tn) / (acc + tn + fn + fp)\n",
    "\n",
    "    #return {'P': P, 'R': R, 'A': A}\n",
    "\n",
    "    print(\"total correct:\", acc, \"total pred:\",total_pred, \"total true:\", total_y)  \n",
    "    print('precision is ',P)\n",
    "    print('recall is ',R)  \n",
    "    print('F1 is ',2*((P*R)/(P+R)))\n",
    "    print('Accuracy is ',A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 10 and top50 most common ICD9 codes for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_top10 = ['401.9','272.4','530.81','250.00','428.0','427.31','414.01','518.81','599.0','584.9']\n",
    "icd_top50 = ['401.9','38.93','428.0','427.31','414.01','96.04','96.6','584.9','250.00','96.71','272.4','518.81','99.04','39.61','599.0','530.81','96.72','272.0', '285.9','88.56','244.9','486','38.91', '285.1','36.15','276.2','496','99.15','995.92','V58.61','507.0','038.9','88.72','585.9','403.90','311','305.1','37.22','412','33.24','39.95','287.5','410.71','276.1','V45.81','424.0', '45.13','V15.82','511.9','37.23']\n",
    "\n",
    "icd10_top10 = ['e78.5','i10','z87.891','k21.9','f32.9','i25.10','n17.9','f41.9','z79.01','z79.4']\n",
    "icd10_top50 = ['e78.5','i10','z87.891','k21.9','f32.9','i25.10','n17.9','f41.9','z79.01','z79.4','e03.9','e11.9','g47.33','d64.9', 'e66.9','i48.91','f17.210','y92.9','z66','j45.909','z79.02','j44.9','d62','02hv33z','n39.0','i12.9','e11.22','e87.1',\n",
    " 'i25.2','n18.9','e87.2','z86.73', 'z95.5', 'z86.718', 'g89.29','i11.0','k59.00','n40.0','n18.3','i48.0','i13.0','g47.00','d69.6','z95.1','m10.9','y92.239','j96.01','j18.9','z23','y92.230']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output variables for storing the abalation runs \n",
    "base_icd = defaultdict(list)\n",
    "prune_icd = defaultdict(list)\n",
    "omissions_icd = defaultdict(list)\n",
    "op_icd = defaultdict(list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the openai models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_4 = ChatOpenAI(model_name = 'gpt-4-32k-0314', openai_api_key=openai.api_key,temperature=0.1,max_tokens=500, deployment_id='gpt-4-32k-0314')\n",
    "llm_35 = ChatOpenAI(model_name = 'gpt-35-turbo-0301', openai_api_key=openai.api_key,temperature=0.1,max_tokens=500,deployment_id='gpt-35-turbo-0301')\n",
    "llm_3 = OpenAI(model_name = 'text-davinci-003', openai_api_key=openai.api_key,temperature=0.1,max_tokens=500, deployment_id='text-davinci-003')\n",
    "\n",
    "llm_list = [llm_4,llm_35,llm_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC Iv ICD-9 coding\n",
    "for model in llm_list:\n",
    "  llm = model\n",
    "  \n",
    "  for k in test_keys9:\n",
    "    diseases,entail,all_omissions = [],[],[]\n",
    "    note = icd9_dict[k][0][0]\n",
    "\n",
    "    # adjust maximum context length for each model\n",
    "    num_tokens = tiktoken_len(note)\n",
    "    if llm.model_name == 'text-davinci-003':\n",
    "      max_tokens = 3000\n",
    "    elif llm.model_name ==  'gpt-35-turbo-0301':\n",
    "      max_tokens = 7000\n",
    "    else:\n",
    "      max_tokens = 30000  \n",
    "    while num_tokens > max_tokens:\n",
    "      delta =  num_tokens - max_tokens\n",
    "      note = note[:-delta*3]\n",
    "      num_tokens = tiktoken_len(note)\n",
    "    \n",
    "\n",
    "    #Extract diseases\n",
    "    diseases = get_diseases(note)\n",
    "    if diseases:\n",
    "      icds = get_icds(note, diseases)\n",
    "      base_icd[k] = icds\n",
    "    else:\n",
    "      base_icd[k] = []  \n",
    "    \n",
    "    #Generate Evidence \n",
    "    evidence = get_evidence(note,diseases)\n",
    "    entail = does_ential(evidence)\n",
    "    if entail:\n",
    "      icds = get_icds(note,entail)\n",
    "      prune_icd[k] = icds\n",
    "    else:\n",
    "      prune_icd[k] = []  \n",
    "    \n",
    "    \n",
    "    #Find omissions\n",
    "    if diseases:\n",
    "      all_omissions = diseases.copy()\n",
    "    else:\n",
    "      all_omissions = []  \n",
    "    for _ in range(3):\n",
    "      \n",
    "      omissions = find_omissions(note,all_omissions)\n",
    "      if not omissions:\n",
    "        break\n",
    "      all_omissions.extend(omissions)\n",
    "    if all_omissions:  \n",
    "      icds = get_icds(note, all_omissions) \n",
    "      omissions_icd[k] = icds\n",
    "    else:\n",
    "      omissions_icd[k] = []  \n",
    "    \n",
    "\n",
    "    # Verify found omissions\n",
    "    evidence = get_evidence(note,all_omissions)\n",
    "    entail = does_ential(evidence)\n",
    "    if entail:\n",
    "      icds = get_icds(note,  entail)\n",
    "      op_icd[k] = icds\n",
    "    else:\n",
    "      op_icd[k] = []  \n",
    "    \n",
    "\n",
    "\n",
    "  print(f'Top 10 Extractions Using {llm.model_name} model:')\n",
    "  icd = icd_top10\n",
    "  \n",
    "  print(\"base \",calculate_metrics_9(omissions_icd, icd))\n",
    "  print(\"prune \",calculate_metrics_9(prune_icd, icd))\n",
    "  print(\"omissions \",calculate_metrics_9(omissions_icd, icd))\n",
    "  print(\" omissions + prune\",calculate_metrics_9(op_icd, icd))  \n",
    "\n",
    "  print(f'Top 50 Extractions Using {llm.model_name} model:')\n",
    "  icd = icd_top50\n",
    "  print(\"base \",calculate_metrics_9(base_icd, icd))\n",
    "  print(\"prune \",calculate_metrics_9(prune_icd, icd))\n",
    "  print(\"omissions \",calculate_metrics_9(omissions_icd, icd))\n",
    "  print(\" omissions + prune\",calculate_metrics_9(op_icd, icd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimiciv_icd_pred = {}\n",
    "for kk,vv in op_icd.items():\n",
    "  mimiciv_icd_pred[kk] = {\"base\":base_icd[kk], \"prune\":prune_icd[kk],\"omissions\":omissions_icd[kk],\"op\":vv}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"YOUR/OUTUT/PATH\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok = True)\n",
    "with open(filename,'w') as outfile:\n",
    "  json.dump(mimiciv_icd_pred, outfile, indent=4, sort_keys = True, default = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_icd10 = defaultdict(list)\n",
    "prune_icd10 = defaultdict(list)\n",
    "omissions_icd10 = defaultdict(list)\n",
    "op_icd10 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC IV ICD-10 coding\n",
    "for model in llm_list:\n",
    "  llm = model\n",
    "  \n",
    "  for k in test_keys10:\n",
    "    diseases,entail,all_omissions = [],[],[]\n",
    "    note = icd10_dict[k][0][0]\n",
    "\n",
    "    # adjust maximum context length for each model\n",
    "    num_tokens = tiktoken_len(note)\n",
    "    if llm.model_name == 'text-davinci-003':\n",
    "      max_tokens = 3000\n",
    "    elif llm.model_name ==  'gpt-35-turbo-0301':\n",
    "      max_tokens = 7000\n",
    "    else:\n",
    "      max_tokens = 30000  \n",
    "    while num_tokens > max_tokens:\n",
    "      delta =  num_tokens - max_tokens\n",
    "      note = note[:-delta*3]\n",
    "      num_tokens = tiktoken_len(note)\n",
    "\n",
    "    # Extract Diseases\n",
    "    diseases = get_diseases(note)\n",
    "    if diseases:\n",
    "      icds = get_icds_10(note, diseases)\n",
    "      base_icd10[k] = icds\n",
    "    else:\n",
    "      base_icd10[k] = []  \n",
    "    \n",
    "    # Generate Evidence\n",
    "    evidence = get_evidence(note,diseases)\n",
    "    entail = does_ential(evidence)\n",
    "    if entail:\n",
    "      icds = get_icds_10(note,entail)\n",
    "      prune_icd10[k] = icds\n",
    "    else:\n",
    "      prune_icd10[k] = []  \n",
    "    \n",
    "    # Find omissions\n",
    "    all_omissions = entail.copy()\n",
    "    for _ in range(3):\n",
    "      omissions = find_omissions(note,all_omissions)\n",
    "      if not omissions:\n",
    "        break\n",
    "      all_omissions.extend(omissions)\n",
    "    if all_omissions:  \n",
    "      icds = get_icds_10(note, all_omissions) \n",
    "      omissions_icd10[k] = icds\n",
    "    else:\n",
    "      omissions_icd10[k] = []  \n",
    "    \n",
    "    # Verify omissions\n",
    "    evidence = get_evidence(note,all_omissions)\n",
    "    entail = does_ential(evidence)\n",
    "    if entail:\n",
    "      icds = get_icds_10(note,  entail)\n",
    "      op_icd10[k] = icds\n",
    "    else:\n",
    "      op_icd10 = []  \n",
    "\n",
    "  print(f'Top 10 Extractions Using {llm.model_name} model:')\n",
    "  icd = icd10_top10\n",
    "  \n",
    "  print(\"base \",calculate_metrics_10(omissions_icd, icd))\n",
    "  print(\"prune \",calculate_metrics_10(prune_icd, icd))\n",
    "  print(\"omissions \",calculate_metrics_10(omissions_icd, icd))\n",
    "  print(\" omissions + prune\",calculate_metrics_10(op_icd, icd))  \n",
    "\n",
    "  print(f'Top 50 Extractions Using {llm.model_name} model:')\n",
    "  icd = icd10_top50\n",
    "  print(\"base \",calculate_metrics_10(base_icd, icd))\n",
    "  print(\"prune \",calculate_metrics_10(prune_icd, icd))\n",
    "  print(\"omissions \",calculate_metrics_10(omissions_icd, icd))\n",
    "  print(\" omissions + prune\",calculate_metrics_10(op_icd, icd))   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimiciv_icd10_pred = {}\n",
    "for kk,vv in op_icd.items():\n",
    "  mimiciv_icd10_pred[kk] = {\"base\":base_icd[kk], \"prune\":prune_icd[kk],\"omissions\":omissions_icd[kk],\"op\":vv}\n",
    "\n",
    "filename = \"YOUR/OUTUT/PATH\"\n",
    "os.makedirs(os.path.dirname(filename), exist_ok = True)\n",
    "with open(filename,'w') as outfile:\n",
    "  json.dump(mimiciv_icd10_pred, outfile, indent=4, sort_keys = True, default = str)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
