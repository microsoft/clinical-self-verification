{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "import clin.llm\n",
    "import datasets\n",
    "import time\n",
    "import openai\n",
    "openai.api_key_path = '/home/chansingh/.OPENAI_KEY'\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import clin.prompts\n",
    "import clin.eval\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: mitclinicalml/clinical-ie\n",
    "# 3 splits here: 'medication_status', 'medication_attr', 'coreference\n",
    "llm = clin.llm.get_llm('gpt-4-0314')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List medications task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = datasets.load_dataset('mitclinicalml/clinical-ie', 'medication_status')\n",
    "val = pd.DataFrame.from_dict(dset['validation'])\n",
    "test = pd.DataFrame.from_dict(dset['test'])\n",
    "df = pd.concat([val, test])\n",
    "nums = np.arange(len(df)).tolist()\n",
    "np.random.default_rng(seed=13).shuffle(nums)\n",
    "dfe = df.iloc[nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = np.arange(len(df)).tolist()\n",
    "np.random.default_rng(seed=13).shuffle(nums)\n",
    "n_shots = 5\n",
    "resps = []\n",
    "for i in tqdm(range(len(nums))):\n",
    "    # print(i)\n",
    "    if i - n_shots < 0:\n",
    "        examples_nums_shot = nums[i - n_shots:] + nums[:i]\n",
    "    else:\n",
    "        examples_nums_shot = nums[i - n_shots: i]\n",
    "    ex_num = nums[i]\n",
    "    prompt = clin.prompts.get_multishot_prompt(df, examples_nums_shot, ex_num)\n",
    "\n",
    "    response = None\n",
    "    while response is None:\n",
    "        try:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "                # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "                # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "            ]\n",
    "            response = llm(messages)\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "    resps.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = df.iloc[nums]\n",
    "dfe['resps'] = resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mets_dict = defaultdict(list)\n",
    "for i in range(len(dfe)):\n",
    "    # print(i)\n",
    "    medications_list_resp = clin.eval.parse_response_medication_list(dfe.iloc[i]['resps'])\n",
    "    mets = clin.eval.eval_med_extraction(medications_list_resp, dfe.iloc[i])\n",
    "    for k in ['precision', 'recall']:\n",
    "        mets_dict[k].append(mets[k])\n",
    "# for resp in dfe['resps'][:3]:\n",
    "    # print(resp, end='\\n\\n')\n",
    "    # print(parse_response_list(resp))\n",
    "    # eval_med_extraction(parse_response_list(resp), dfe.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'recall {np.mean(mets_dict[\"recall\"]):.3f} precision {np.mean(mets_dict[\"precision\"]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    {'id': 'chatcmpl-7BI1T2IJglWMAuvy5n6hGxktfZ4lD...\n",
       "28    {'id': 'chatcmpl-7BI1cePy4bg9FvXc7iCfxF6eydA8g...\n",
       "59    {'id': 'chatcmpl-7BI1gn09aahJcqKoxnBPnzgJMDuyB...\n",
       "18    {'id': 'chatcmpl-7BI1lFcX9uWnYMuyZEZim6o2qJAJ8...\n",
       "34    {'id': 'chatcmpl-7BIYX2Fhhf5e1261d7gKwD8RLUbCK...\n",
       "                            ...                        \n",
       "21    {'id': 'chatcmpl-7BInBWhTktu3P4w5XlkTXmfuqKw0B...\n",
       "57    {'id': 'chatcmpl-7BInSE7kEm02xakRS7Xiwx65XQ5K8...\n",
       "52    {'id': 'chatcmpl-7BIncESKfIqSPZNmhnuTLK8skpnjT...\n",
       "4     {'id': 'chatcmpl-7BInj6910TCO5rISKILvfSiuC8Tm7...\n",
       "55    {'id': 'chatcmpl-7BInuPiYQ4vxZtrJKvQr5eKFXGX3B...\n",
       "Name: resps, Length: 105, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfe['resps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
