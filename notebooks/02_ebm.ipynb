{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import clin.llm\n",
    "import clin.parse\n",
    "import openai\n",
    "openai.api_key_path = '/home/chansingh/.OPENAI_KEY'\n",
    "from typing import List\n",
    "results_dir = '../results/'\n",
    "from clin.config import PATH_REPO\n",
    "from clin.modules.ebm import extract, omission, prune, evidence\n",
    "import clin.eval.ebm\n",
    "import clin.eval.eval\n",
    "from clin.modules import ebm\n",
    "import joblib\n",
    "import imodelsx.process_results\n",
    "\n",
    "r = imodelsx.process_results.get_results_df(results_dir, use_cached=False)\n",
    "r = r[r.dataset_name == 'ebm']\n",
    "row = r[(r.n_shots == 5) * (r.checkpoint == 'text-davinci-003')].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show metrics\n",
    "row_df = pd.DataFrame(\n",
    "    pd.Series({k: row[k] for k in row.keys() if \"___\" in k}).round(3)\n",
    ").T\n",
    "rc = row_df[[c for c in row_df.columns if \"___\" in c]]\n",
    "# create multindex columns by splitting on '___'\n",
    "rc = rc.rename(columns={c: tuple(c.split(\"___\")) for c in rc.columns})\n",
    "\n",
    "# convert tuple column names to multiindex\n",
    "rc.columns = pd.MultiIndex.from_tuples(rc.columns)\n",
    "rc = rc.T.reset_index()\n",
    "rc = (\n",
    "    rc.rename(\n",
    "        columns={\n",
    "            \"level_0\": \"\",\n",
    "            \"level_1\": \"Verifiers\",\n",
    "        }\n",
    "    )\n",
    "    .pivot_table(index=\"Verifiers\", columns=\"\", values=0)\n",
    "    .round(3)\n",
    ")\n",
    "# rc.index = [x.replace(\"list_\", \"\") for x in rc.index.values]\n",
    "cols = {\n",
    "    \"f1\": \"F1\",\n",
    "    \"precision\": \"Precision\",\n",
    "    \"recall\": \"Recall\",\n",
    "}\n",
    "rows = {\n",
    "    \"original\": \"Original\",\n",
    "    \"ov\": \"Omission\",\n",
    "    \"pv\": \"Prune\",\n",
    "    \"ov_pv\": \"Omission + Prune\",\n",
    "    \"ov_pv_ev\": \"Omission + Prune + Evidence\",\n",
    "}\n",
    "(\n",
    "    rc[list(cols.keys())]\n",
    "    .rename(columns=cols)\n",
    "    .loc[list(rows.keys())]\n",
    "    .rename(index=rows)\n",
    "    .style.format(precision=3)\n",
    "    .background_gradient(cmap=\"Blues\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load(join(PATH_REPO, 'data', 'ebm', 'ebm_interventions_cleaned.pkl'))\n",
    "df = df.iloc[:100]\n",
    "nums = np.arange(len(df)).tolist()\n",
    "np.random.default_rng(seed=13).shuffle(nums)\n",
    "dfe = df.iloc[nums]\n",
    "# n = len(dfe)\n",
    "# llm = clin.llm.get_llm('text-davinci-003')\n",
    "\n",
    "# compare lists\n",
    "l1 = [sorted(l) for l in dfe[\"interventions\"].values.tolist()]\n",
    "# l1 = r['list_ov']\n",
    "# l1 = r['list_ov']\n",
    "# l1 = r['list_ov_pv_ev']\n",
    "l2 = row['list_ov_pv']\n",
    "for i in range(len(l1)):\n",
    "    l1_, l2_ = clin.eval.ebm.process_ebm_lists(l1[i], l2[i])\n",
    "    # if set(l1_) == set(l2_) and len(set(l1_)) > 2:\n",
    "    if len(set(l1_)) > 3:\n",
    "        print(dfe.iloc[i]['doc'])\n",
    "        print(i)\n",
    "        print(sorted(l1[i]))\n",
    "        print(sorted(l2[i]))\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load(join(PATH_REPO, 'data', 'ebm', 'ebm_interventions_cleaned.pkl'))\n",
    "df = df.iloc[:100]\n",
    "nums = np.arange(len(df)).tolist()\n",
    "np.random.default_rng(seed=13).shuffle(nums)\n",
    "dfe = df.iloc[nums]\n",
    "# n = len(dfe)\n",
    "# llm = clin.llm.get_llm('text-davinci-003')\n",
    "\n",
    "# compare lists\n",
    "l1 = [sorted(l) for l in dfe[\"interventions\"].values.tolist()]\n",
    "# l1 = r['list_ov']\n",
    "# l1 = r['list_ov']\n",
    "# l1 = r['list_ov_pv_ev']\n",
    "l2 = row['list_ov_pv']\n",
    "for i in range(len(l1)):\n",
    "    l1_, l2_ = clin.eval.ebm.process_ebm_lists(l1[i], l2[i])\n",
    "    if set(l1_) != set(l2_):\n",
    "        print(dfe.iloc[i]['doc'])\n",
    "        print(i)\n",
    "        print(sorted(l1[i]))\n",
    "        print(sorted(l2[i]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at validation data\n",
    "dfv = joblib.load(join(PATH_REPO, 'data', 'ebm', 'ebm_interventions_cleaned.pkl')).iloc[100:]\n",
    "for i in range(len(dfv)):\n",
    "    row = dfv.iloc[i]\n",
    "    print(row['doc'])\n",
    "    print(clin.parse.list_to_bullet_str(row['interventions']))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
